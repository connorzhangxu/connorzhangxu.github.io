<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>Subgradient Method | Connorzx</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="次梯度方法(subgradient method)是传统的梯度下降方法的拓展，用来处理不可导的凸函数。它的优势是比传统方法处理问题范围大，劣势是算法收敛速度慢。但是，由于它对不可导函数有很好的处理方法，所以学习它还是很有必要的。">
<meta property="og:type" content="article">
<meta property="og:title" content="Subgradient Method">
<meta property="og:url" content="http://yoursite.com/2015/09/10/Mathematic-Subgradient Method/index.html">
<meta property="og:site_name" content="Connorzx">
<meta property="og:description" content="次梯度方法(subgradient method)是传统的梯度下降方法的拓展，用来处理不可导的凸函数。它的优势是比传统方法处理问题范围大，劣势是算法收敛速度慢。但是，由于它对不可导函数有很好的处理方法，所以学习它还是很有必要的。">
<meta property="og:image" content="http://images2015.cnblogs.com/blog/437988/201509/437988-20150910145519106-351942480.jpg">
<meta property="og:updated_time" content="2016-03-03T12:47:41.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Subgradient Method">
<meta name="twitter:description" content="次梯度方法(subgradient method)是传统的梯度下降方法的拓展，用来处理不可导的凸函数。它的优势是比传统方法处理问题范围大，劣势是算法收敛速度慢。但是，由于它对不可导函数有很好的处理方法，所以学习它还是很有必要的。">
<meta name="twitter:image" content="http://images2015.cnblogs.com/blog/437988/201509/437988-20150910145519106-351942480.jpg">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img src="/photo.jpg" class="js-avatar" style="width: 100%;height: 100%;opacity: 1;">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Connorzx</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						<li>Links</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">Home</a></li>
				        
							<li><a href="/archives">Article</a></li>
				        
							<li><a href="/tags/essay">Essay</a></li>
				        
							<li><a href="/about">About</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/connorzhangxu" title="github">github</a>
					        
								<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/connorzx" title="zhihu">zhihu</a>
					        
								<a class="facebook" target="_blank" href="https://www.facebook.com/connor.zhang.77" title="facebook">facebook</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Build-Blog/" style="font-size: 10px;">Build Blog</a> <a href="/tags/Cluster-Analysis/" style="font-size: 10px;">Cluster Analysis</a> <a href="/tags/Convex-Optimization/" style="font-size: 10px;">Convex Optimization</a> <a href="/tags/Error-Detection/" style="font-size: 10px;">Error Detection</a> <a href="/tags/Large-Deviations/" style="font-size: 10px;">Large Deviations</a> <a href="/tags/Matrix-Analysis/" style="font-size: 20px;">Matrix Analysis</a> <a href="/tags/Neural-Network/" style="font-size: 10px;">Neural Network</a> <a href="/tags/PCA/" style="font-size: 10px;">PCA</a> <a href="/tags/Recommendation-System/" style="font-size: 10px;">Recommendation System</a> <a href="/tags/Regression/" style="font-size: 10px;">Regression</a> <a href="/tags/SVM/" style="font-size: 10px;">SVM</a> <a href="/tags/essay/" style="font-size: 20px;">essay</a> <a href="/tags/matlab/" style="font-size: 10px;">matlab</a> <a href="/tags/matrix-optimazation/" style="font-size: 10px;">matrix optimazation</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://www.zhihu.com/">知乎</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://www.guokr.com/">果壳</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://songshuhui.net/">科学松鼠会</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://emuch.net/bbs/">小木虫</a>
			        
			        </div>
				</section>
				

				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Connorzx</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img src="/photo.jpg" class="js-avatar" style="width: 100%;height: 100%;opacity: 1;">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Connorzx</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">Home</a></li>
		        
					<li><a href="/archives">Article</a></li>
		        
					<li><a href="/tags/essay">Essay</a></li>
		        
					<li><a href="/about">About</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/connorzhangxu" title="github">github</a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/connorzx" title="zhihu">zhihu</a>
			        
						<a class="facebook" target="_blank" href="https://www.facebook.com/connor.zhang.77" title="facebook">facebook</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-Mathematic-Subgradient Method" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/09/10/Mathematic-Subgradient Method/" class="article-date">
  	<time datetime="2015-09-10T02:50:16.000Z" itemprop="datePublished">2015-09-10</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Subgradient Method
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Convex-Optimization/">Convex Optimization</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Mathematic/">Mathematic</a>
	</div>


        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
         <!--02-->
        <div id="toc" class="toc-article">
    <div class="toc-title">Contents</div>
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#次梯度（subgradient）"><span class="toc-text">次梯度（subgradient）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-定义"><span class="toc-text">1.定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-性质"><span class="toc-text">2. 性质</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-扩展"><span class="toc-text">3. 扩展</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#次梯度方法"><span class="toc-text">次梯度方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#应用（duality-subgradient-method）"><span class="toc-text">应用（duality+subgradient method）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#用法1"><span class="toc-text">用法1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#用法2"><span class="toc-text">用法2</span></a></li></ol></li></ol>
</div>
      
        <blockquote>
<p>次梯度方法(<a href="https://en.wikipedia.org/wiki/Subgradient\_method" target="_blank" rel="external">subgradient method</a>)是传统的梯度下降方法的拓展，用来处理不可导的凸函数。它的优势是比传统方法处理问题范围大，劣势是算法收敛速度慢。但是，由于它对不可导函数有很好的处理方法，所以学习它还是很有必要的。</p>
</blockquote>
<a id="more"></a>
<h2 id="次梯度（subgradient）"><a href="#次梯度（subgradient）" class="headerlink" title="次梯度（subgradient）"></a>次梯度（<a href="https://sv.wikipedia.org/wiki/Subgradient" target="_blank" rel="external">subgradient</a>）</h2><h3 id="1-定义"><a href="#1-定义" class="headerlink" title="1.定义"></a>1.定义</h3><p>所谓次梯度，定义是这样的：<br>$$\partial f=\{g|f(x)\ge f(x_0)+g^T(x-x_0),\forall x \in domf，f：R^n \to R\}$$<br>用图片表示，即为<br><img src="http://images2015.cnblogs.com/blog/437988/201509/437988-20150910145519106-351942480.jpg" alt=""><br>也就是，在$x_0$处所有的支撑超平面的超平面的法向量$g^T$的转置$g$构成的集合。即$g \in \partial f$。</p>
<p>一维次梯度称为次导数，通过求函数在点的每一分量的次导数可以求出函数在该点的次梯度。</p>
<p>可以证明，在点$x_0$的次导数的集合是一个非空闭区间$[a,b]$，其中a和b是单侧极限<br>$$a = \lim \limits_{x \to x_0^-}  \frac{f(x) - f(x_0)}{x - x_0},b = \lim \limits_{x \to x_0^+}  \frac{f(x) - f(x_0)}{x - x_0}$$<br>举例：$y=|x|$在$x=0$的次梯度为$[-1,1]$，它们一定存在，且满足$a≤b$。所有次导数的集合$[a,b]$称为函数$f$在$x_0$的次导数。</p>
<p>举例：$y=|x|$在$x=0$的次梯度为$[-1,1]$</p>
<p><strong>注：</strong> 如果$f$可导，那么它的次梯度等于它的梯度。如果不可导，在最优点处，$0 \in \partial f$</p>
<h3 id="2-性质"><a href="#2-性质" class="headerlink" title="2. 性质"></a>2. 性质</h3><ul>
<li>数乘不变性。$\forall \alpha \ge 0,\partial (\alpha f)(x)=\alpha \partial f(x)$</li>
<li>加法不变性。$f=f_1+\ldots+f_m,\partial f(x)=\partial f_1(x)+\ldots+\partial f_m(x)$</li>
<li>仿射特性。如果$f$是凸函数，那么$\partial f(Ax+b)=A^T \partial f(Ax+b)$</li>
</ul>
<h3 id="3-扩展"><a href="#3-扩展" class="headerlink" title="3. 扩展"></a>3. 扩展</h3><p>对于一个凸优化问题，<br>$$\min f_0(z),s.t. f_i(z) \le x，Ax=y$$<br>对偶问题为<br>$$\max g(\lambda)-x^T\lambda-y^T v$$</p>
<p>那么，由全局扰动不等式，我们有<br>$$f(x,y) \ge f(\hat x,\hat y)-{\lambda^*}^T(x-\hat x)-{v^*}^T(y-\hat y)$$</p>
<p>其中，假设Slater条件成立，且在$x=\hat x,y=\hat y$处满足强对偶性。</p>
<p>从上式可以看出，$-（\lambda^*,v^*）\in \partial f(\hat x,\hat y)$</p>
<p>也就是说$（\lambda^*,v^*）^T$是$(\hat x,\hat y)$处的一个支持超平面的法线。</p>
<h2 id="次梯度方法"><a href="#次梯度方法" class="headerlink" title="次梯度方法"></a>次梯度方法</h2><p>首先，我们想到的方法是推广一下梯度下降法。<br>$$x^{(k+1)}=x^{(k)}-\alpha_k g^{(k)}$$<br>其中，$g^{(k)} \in \partial f(x^{(k)})$</p>
<p>然而，$-g^{(k)}$可能不再是下降方向。所以常用的方式是一直保留最小的函数值，直到结果收敛。<br>$$f_{best}^{(k)} = \min \{  f_{best}^{(k)},f({x^{(k)}}) \} $$</p>
<p><strong>注：</strong>步长选择和收敛性分析在这里不再赘述。（回头有精力再写）</p>
<h2 id="应用（duality-subgradient-method）"><a href="#应用（duality-subgradient-method）" class="headerlink" title="应用（duality+subgradient method）"></a>应用（duality+subgradient method）</h2><h3 id="用法1"><a href="#用法1" class="headerlink" title="用法1"></a>用法1</h3><p>对于凸优化问题<br>$$\min f_0(z),s.t. f_i(z) \le x$$<br>对偶问题为<br>$$\max g(\lambda),s.t. \lambda \ge 0$$<br>其中，$g(\lambda)=\inf \limits_x L(x,\lambda)=f_0(x^*(\lambda))+\sum \limits_{i=1}^{m} \lambda_i f_i(x^*(\lambda))$<br>假设Slater条件成立，那么我们可以通过解决对偶问题求得原问题的解。</p>
<p>那么，使用次梯度方法时，<strong>需要使得</strong><br>$$\lambda^{(k+1)}=(\lambda^{(k)}-\alpha_k h),h \in \partial (-g)(\lambda^{(k)})$$</p>
<p>也就是，<br>$$h=-(f_1(x^*(\lambda)),\ldots,f_m(x^*(\lambda))) \in \partial (-g)(\lambda^{(k)})$$</p>
<h3 id="用法2"><a href="#用法2" class="headerlink" title="用法2"></a>用法2</h3><p>对比原来的$ \nabla L(x,\lambda ^ * ) = 0 $<br>这里经常用的是 $0 \in \nabla L(x,\lambda ^ * ) $</p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/12/19/Mathematic-Matrix Inner Product and Schur Complement/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          Matrix Inner Product and Schur Complement
        
      </div>
    </a>
  
  
    <a href="/2015/08/26/Mathematic-Projection Matrix,LSE and SVD Decomposition/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Projection Matrix,LSE and SVD Decomposition</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share_jia">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">Share to: &nbsp; </span>
		<a class="jiathis_button_facebook"></a> 
    <a class="jiathis_button_twitter"></a>
    <a class="jiathis_button_plus"></a> 
    <a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>






<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="Mathematic-Subgradient Method" data-title="Subgradient Method" data-url="http://yoursite.com/2015/09/10/Mathematic-Subgradient Method/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"true"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2017 Connorzx
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: undefined,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: undefined
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>

<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config(null);
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
</body>
</html>